# Task 1.1: Táº¡o Topic Demo vá»›i Multiple Partitions

## ğŸ“‹ Má»¥c tiÃªu
Implement tá»± Ä‘á»™ng táº¡o topics Ä‘á»ƒ há»c vá» Kafka partitioning strategy vÃ  ordering guarantees.

## âœ… Nhá»¯ng gÃ¬ Ä‘Ã£ Ä‘Æ°á»£c implement

### 1. **KafkaTopicConfig.cs** - Topic Configuration Definition
- `KafkaTopicConfig` class: MÃ´ táº£ má»™t topic (name, partitions, replication factor, configs)
- `ModuleATopics` class: Äá»‹nh nghÄ©a 5 topics demo:

```
user-events        (3 partitions) - Learn partitioning by userId key
orders             (3 partitions) - Learn ordering per orderId  
payments           (5 partitions) - Learn higher throughput
notifications      (1 partition)  - Learn no-key publishing
order-processing.DLQ (3 partitions) - Learn DLQ pattern
```

### 2. **KafkaTopicProvisioningService.cs** - Auto-Create Topics on Startup
- Implements `IHostedService` => tá»± Ä‘á»™ng cháº¡y khi app startup
- Kiá»ƒm tra topics Ä‘Ã£ tá»“n táº¡i => bá» qua (idempotent)
- Táº¡o topics khÃ´ng tá»“n táº¡i vá»›i config tá»« `ModuleATopics`
- Log chi tiáº¿t partition metadata

### 3. **Program.cs** - Register Service
```csharp
builder.Services.AddHostedService(sp => 
    new KafkaTopicProvisioningService(
        kafkaBootstrapServers,
        sp.GetRequiredService<ILogger<KafkaTopicProvisioningService>>()));
```

### 4. **KafkaController.cs** - REST Endpoints cho Task 1.1

#### Endpoint 1: List all topics
```http
GET /api/kafka/topics
```

**Response:**
```json
{
  "topics": ["user-events", "orders", "payments", "notifications", "order-processing.DLQ"],
  "count": 5
}
```

#### Endpoint 2: Get topic metadata (partitions, leaders, replicas)
```http
GET /api/kafka/topics/{topicName}/metadata
```

**Example:** `GET /api/kafka/topics/user-events/metadata`

**Response:**
```json
{
  "topic": "user-events",
  "partitionCount": 3,
  "partitions": [
    {
      "partitionId": 0,
      "leader": 1,
      "replicas": [1],
      "inSyncReplicas": [1]
    },
    {
      "partitionId": 1,
      "leader": 1,
      "replicas": [1],
      "inSyncReplicas": [1]
    },
    {
      "partitionId": 2,
      "leader": 1,
      "replicas": [1],
      "inSyncReplicas": [1]
    }
  ]
}
```

#### Endpoint 3: Create custom topic
```http
POST /api/kafka/topics
Content-Type: application/json

{
  "name": "my-custom-topic",
  "numPartitions": 3,
  "replicationFactor": 1,
  "configs": {
    "retention.ms": "604800000",
    "compression.type": "snappy"
  }
}
```

#### Endpoint 4: Initialize all Module A topics
```http
POST /api/kafka/init-module-a-topics
```

**Response:**
```json
{
  "message": "Module A topics initialization completed",
  "results": [
    {
      "topic": "user-events",
      "status": "created",
      "partitions": 3,
      "replicationFactor": 1
    },
    {
      "topic": "orders",
      "status": "created",
      "partitions": 3,
      "replicationFactor": 1
    },
    ...
  ]
}
```

## ğŸš€ CÃ¡ch sá»­ dá»¥ng

### Option 1: Automatic on Startup (Recommended)
1. Start the API application
2. Check logs for topic creation messages
3. Endpoints tá»± Ä‘á»™ng available

### Option 2: Manual via REST API
1. Má»Ÿ Swagger UI: `http://localhost:5224/swagger`
2. Navigate to `KafkaController`
3. Test endpoints:
   - `POST /api/kafka/init-module-a-topics` (táº¡o táº¥t cáº£)
   - `GET /api/kafka/topics` (list)
   - `GET /api/kafka/topics/{topicName}/metadata` (xem chi tiáº¿t)

### Option 3: Using cURL
```bash
# List topics
curl http://localhost:5224/api/kafka/topics

# Get topic metadata
curl http://localhost:5224/api/kafka/topics/user-events/metadata

# Create custom topic
curl -X POST http://localhost:5224/api/kafka/topics \
  -H "Content-Type: application/json" \
  -d '{
    "name": "test-topic",
    "numPartitions": 3,
    "replicationFactor": 1
  }'

# Initialize Module A topics
curl -X POST http://localhost:5224/api/kafka/init-module-a-topics
```

## ğŸ“– Kiáº¿n thá»©c há»c Ä‘Æ°á»£c

### 1. Topic Structure
```
Topic: user-events (3 partitions)
â”‚
â”œâ”€â”€ Partition 0 (Leader: Broker 1)
â”‚   â””â”€â”€ Messages: [offset 0, 1, 2, ...]
â”œâ”€â”€ Partition 1 (Leader: Broker 1)
â”‚   â””â”€â”€ Messages: [offset 0, 1, 2, ...]
â””â”€â”€ Partition 2 (Leader: Broker 1)
    â””â”€â”€ Messages: [offset 0, 1, 2, ...]
```

### 2. Partitioning Strategy
```
Message vá»›i Key
â”œâ”€ Key="user-1" => hash(user-1) % 3 = Partition 0
â”œâ”€ Key="user-2" => hash(user-2) % 3 = Partition 1
â””â”€ Key="user-3" => hash(user-3) % 3 = Partition 0 (cÃ³ thá»ƒ cÃ¹ng partition)

=> Messages tá»« cÃ¹ng user Ä‘i vÃ o cÃ¹ng partition
=> Äáº£m báº£o ordering per user (trong 1 partition)
```

### 3. Ordering Guarantees
```
Partition 0: [User1_Event1, User1_Event2, User1_Event3]
             => Xá»­ lÃ½ tuáº§n tá»±, ordering guaranteed

Partition 1: [User2_Event1, User2_Event2]
Partition 2: [User3_Event1]

=> Partitions khÃ¡c nhau cÃ³ thá»ƒ xá»­ lÃ½ song song
=> NhÆ°ng User1 events luÃ´n ordered
```

## â“ Self-Check Questions

1. **Partition lÃ  gÃ¬?**
   - A) Má»™t segment file
   - B) ÄÆ¡n vá»‹ song parallel, append-only log âœ“
   - C) Má»™t consumer
   - D) Má»™t broker

2. **Key dÃ¹ng Ä‘á»ƒ lÃ m gÃ¬?**
   - A) Encrypt message
   - B) XÃ¡c Ä‘á»‹nh partition (hash(key) % partition_count) âœ“
   - C) Identify consumer
   - D) Validate message

3. **Ordering Ä‘Æ°á»£c Ä‘áº£m báº£o á»Ÿ level nÃ o?**
   - A) Topic level
   - B) Consumer level
   - C) Partition level âœ“
   - D) Message level

4. **3 partitions topic cÃ³ máº¥y consumer Ä‘á»ƒ Ä‘áº¡t parallelism tá»‘i Ä‘a?**
   - A) 1
   - B) 2
   - C) 3 âœ“
   - D) 5

## ğŸ”§ Troubleshooting

### Topic creation fails with "Topic already exists"
```
Solution: Delete topic first or check topic list
curl http://localhost:5224/api/kafka/topics
```

### Broker not reachable
```
Kiá»ƒm tra Docker:
docker ps | grep kafka
docker logs <kafka-container-id>

Kiá»ƒm tra appsettings.json:
"Kafka:BootstrapServers": "localhost:9092"  
// hoáº·c "kafka:9092" náº¿u tá»« Docker
```

### Partitions = 0 hoáº·c khÃ´ng tháº¥y partitions
```
Topic cÃ³ thá»ƒ chÆ°a fully propagate
Äá»£i vÃ i giÃ¢y rá»“i retry
curl http://localhost:5224/api/kafka/topics/user-events/metadata
```

## ğŸ“Š Output Log Example

```
ğŸš€ [Task 1.1] Starting Kafka Topic Provisioning...

ğŸ“‹ Existing topics: 

ğŸ“ Creating topic: user-events
   â””â”€ Partitions: 3
   â””â”€ Replication Factor: 1
   â””â”€ Configs: retention.ms=604800000, compression.type=snappy
âœ… Topic 'user-events' created successfully

ğŸ“ Creating topic: orders
   â””â”€ Partitions: 3
   â””â”€ Replication Factor: 1
   â””â”€ Configs: retention.ms=2592000000, compression.type=snappy
âœ… Topic 'orders' created successfully

... (more topics) ...

âœ… [Task 1.1] Topic Provisioning completed successfully!
```

## ğŸ¯ Next Step: Module A - Task 1.2
Implement consumer demo Ä‘á»ƒ:
1. Consume tá»« `user-events` topic
2. Log offset, partition, key information
3. Verify ordering per key

---

**Task 1.1 Status: âœ… COMPLETE**
- [x] Topic config definition
- [x] Auto-provisioning service
- [x] REST endpoints
- [x] Logging & monitoring
